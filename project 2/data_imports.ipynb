{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6e21f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xamuc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import importlib\n",
    "import tools\n",
    "importlib.reload(tools) \n",
    "from tools import *\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import itertools\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest    \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorized_mape(y_true, y_pred, q=0.95):\n",
    "    errors = np.abs((y_true - y_pred) / y_true)\n",
    "    threshold = np.quantile(errors, q)  # cap top q% of errors\n",
    "    errors = np.clip(errors, 0, threshold)\n",
    "    return errors.mean()\n",
    "\n",
    "def score_preds_cv(X, y, model_tup, n_splits=5):\n",
    "    score_df = pd.DataFrame(columns=['model','metric','fold','set','score'])\n",
    "    preds = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    model_name, model = model_tup\n",
    "    iter_name = model_name\n",
    "    preds[iter_name] = {'train_p':[],'train_t':[],'val_p':[],'val_t':[]}\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Fit and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        preds[iter_name]['train_p'].append(y_pred_train)\n",
    "        preds[iter_name]['val_p'].append(y_pred_val)\n",
    "        preds[iter_name]['train_t'].append(y_train)\n",
    "        preds[iter_name]['val_t'].append(y_val)\n",
    "\n",
    "        # Compute metrics\n",
    "        sets = [['train_p', y_train, y_pred_train], ['val_p', y_val, y_pred_val]]\n",
    "        for set_name, truth, pred in sets:\n",
    "            for i, metric in enumerate(metrics):\n",
    "                score_df.loc[len(score_df)] = [\n",
    "                    model_name, metric_names[i], fold+1, set_name, metric(truth, pred)\n",
    "                ]\n",
    "\n",
    "    # ------- Summary: mean ± std per metric per model -------\n",
    "    score_df = score_df.groupby(['model','metric','set']).score.agg(['mean']).reset_index()\n",
    "    score_df['score']=score_df['mean']\n",
    "    score_df.drop('mean',axis=1,inplace=True)\n",
    "    return score_df, preds\n",
    "\n",
    "def score_preds_grid_cv(X, y, grid, n_splits=5):\n",
    "    score_df = pd.DataFrame(columns=['model','metric','fold','set','score'])\n",
    "    preds = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    for ps in grid:\n",
    "        model_name, model = ps['model']\n",
    "\n",
    "        iter_name = model_name\n",
    "        preds[iter_name] = {'train_p':[],'train_t':[],'val_p':[],'val_t':[]}\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Fit and predict\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_val = model.predict(X_val)\n",
    "\n",
    "            preds[iter_name]['train_p'].append(y_pred_train)\n",
    "            preds[iter_name]['val_p'].append(y_pred_val)\n",
    "            preds[iter_name]['train_t'].append(y_train)\n",
    "            preds[iter_name]['val_t'].append(y_val)\n",
    "\n",
    "            # Compute metrics\n",
    "            sets = [['train_p', y_train, y_pred_train], ['val_p', y_val, y_pred_val]]\n",
    "            for set_name, truth, pred in sets:\n",
    "                for i, metric in enumerate(metrics):\n",
    "                    score_df.loc[len(score_df)] = [\n",
    "                        model_name, metric_names[i], fold+1, set_name, metric(truth, pred)\n",
    "                    ]\n",
    "\n",
    "    # ------- Summary: mean ± std per metric per model -------\n",
    "    score_df = score_df.groupby(['model','metric','set']).score.agg(['mean']).reset_index()\n",
    "    score_df['score']=score_df['mean']\n",
    "    score_df.drop('mean',axis=1,inplace=True)\n",
    "    return score_df, preds\n",
    "\n",
    "def score_preds_grid_tts(X, y, score_df, preds, grid, test_size=0.2):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "    for ps in grid:\n",
    "        model_name, model = ps['model']\n",
    "        iter_name = model_name\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        \n",
    "        preds[iter_name] = {'train_p':[],'train_t':[],'val_p':[],'val_t':[]}\n",
    "        preds[iter_name]['train_p'].append(y_pred_train)\n",
    "        preds[iter_name]['val_p'].append(y_pred_val)\n",
    "        preds[iter_name]['train_t'].append(y_train)\n",
    "        preds[iter_name]['val_t'].append(y_val)\n",
    "        \n",
    "        sets = [['train_p',y_train, y_pred_train], ['val_p', y_val, y_pred_val]]\n",
    "        for set_name, truth, pred in sets:\n",
    "            for i in range(len(metrics)):\n",
    "                score_df.loc[len(score_df)] = [model_name, metric_names[i],set_name, metrics[i](truth, pred)]\n",
    "    return score_df, preds\n",
    "\n",
    "def overfit_table(df1, df2, metric_names, df_names=['df1', 'df2']):\n",
    "    # Pivot both dfs\n",
    "    df1_p = df1.pivot(index=['model', 'metric'], columns='set', values='score')\n",
    "    df2_p = df2.pivot(index=['model', 'metric'], columns='set', values='score')\n",
    "    \n",
    "    # Compute differences\n",
    "    df1_diff = df1_p['train_p'] - df1_p['val_p']\n",
    "    df2_diff = df2_p['train_p'] - df2_p['val_p']\n",
    "    \n",
    "    # Put them into a dict\n",
    "    d = {df_names[0]: df1_diff, df_names[1]: df2_diff}\n",
    "    \n",
    "    # Create output DataFrame\n",
    "    overfit_df = pd.DataFrame(columns=metric_names, index=df_names)\n",
    "    \n",
    "    for key, df in d.items():\n",
    "        for metric in metric_names:\n",
    "            # Select all values for this metric across models\n",
    "            vals = df.xs(metric, level='metric')\n",
    "            overfit_df.loc[key, metric] = trim_mean(vals, 0.1)\n",
    "    \n",
    "    return overfit_df\n",
    "\n",
    "\n",
    "class EstimatorWrapper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Make any estimator appear as a single, non-iterable object to skopt/NumPy.\"\"\"\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.estimator_.transform(X)\n",
    "\n",
    "    # keep it sklearn-friendly\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"estimator\": self.estimator}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if \"estimator\" in params:\n",
    "            self.estimator = params[\"estimator\"]\n",
    "        return self\n",
    "    \n",
    "class DataSizeLogger(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): self.logs_ = []\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        msg = f\"[DataSizeLogger] Samples: {X.shape[0]}, Features: {X.shape[1]}\"\n",
    "        self.logs_.append(msg)\n",
    "        print(msg)  # shows when n_jobs=1\n",
    "        return X\n",
    "\n",
    "class FeatureLogger(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        print(f\"[FeatureLogger] Input features: {self.n_features_in_}, Output features: {X.shape[1]}\")\n",
    "        return X\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [mean_squared_error, mean_absolute_percentage_error, winsorized_mape, r2_score]\n",
    "metric_names = ['MSE', 'MAPE', 'wMAPE','R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686af5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(\"Xtrain1.pkl\")\n",
    "Y= pd.DataFrame(np.load(\"Ytrain1.npy\"))\n",
    "df = X.copy()\n",
    "df['target'] = Y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
